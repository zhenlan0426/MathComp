{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T15:26:05.532398Z","iopub.status.busy":"2024-05-18T15:26:05.532092Z","iopub.status.idle":"2024-05-18T15:28:20.516425Z","shell.execute_reply":"2024-05-18T15:28:20.515488Z","shell.execute_reply.started":"2024-05-18T15:26:05.532371Z"},"papermill":{"duration":18.075198,"end_time":"2024-02-29T09:25:25.295954","exception":false,"start_time":"2024-02-29T09:25:07.220756","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip uninstall -y torch -q\n","!pip install --no-index --find-links=/kaggle/input/vllm-whl -U vllm -q\n","# keep data in float16 to avoid OOM\n","file_path = '/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py'\n","with open(file_path, 'r') as file:\n","    file_contents = file.readlines()\n","file_contents = [line for line in file_contents if \"logits = logits.float()\" not in line]\n","with open(file_path, 'w') as file:\n","    file.writelines(file_contents)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T15:28:37.929204Z","iopub.status.busy":"2024-05-18T15:28:37.928832Z","iopub.status.idle":"2024-05-18T15:32:26.834697Z","shell.execute_reply":"2024-05-18T15:32:26.833837Z","shell.execute_reply.started":"2024-05-18T15:28:37.929173Z"},"trusted":true},"outputs":[],"source":["from vllm import LLM, SamplingParams\n","import numpy as np\n","from transformers import LlamaForSequenceClassification\n","import torch\n","torch.backends.cuda.enable_mem_efficient_sdp(False)\n","llm = LLM(model=\"/kaggle/input/deepseek-math\",\n","          dtype='half',\n","          enforce_eager=True,\n","          gpu_memory_utilization=0.99,\n","          swap_space=4,\n","          max_model_len=2048,\n","          kv_cache_dtype=\"fp8_e5m2\",\n","          tensor_parallel_size=1)\n","\n","tokenizer = llm.get_tokenizer()\n","\n","prm_tokenizer = tokenizer\n","prm_model = LlamaForSequenceClassification.from_pretrained('/kaggle/input/prm-code',\\\n","                                                    num_labels=1,\\\n","                                                    device_map=\"cuda:1\",\n","                                                    torch_dtype=\"auto\",\n","                                                    ignore_mismatched_sizes=True,\n","                                                    ).eval()\n","\n","base_model = prm_model.model\n","prm_model.score.load_state_dict(torch.load('/kaggle/input/prm-code/model_score3_code.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T15:36:39.878474Z","iopub.status.busy":"2024-05-18T15:36:39.877636Z","iopub.status.idle":"2024-05-18T15:36:39.882549Z","shell.execute_reply":"2024-05-18T15:36:39.881546Z","shell.execute_reply.started":"2024-05-18T15:36:39.878442Z"},"trusted":true},"outputs":[],"source":["import aimo\n","env = aimo.make_env()\n","iter_test = env.iter_test()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T15:34:18.428665Z","iopub.status.busy":"2024-05-18T15:34:18.427853Z","iopub.status.idle":"2024-05-18T15:34:18.435188Z","shell.execute_reply":"2024-05-18T15:34:18.434161Z","shell.execute_reply.started":"2024-05-18T15:34:18.428632Z"},"trusted":true},"outputs":[],"source":["logit2prob = lambda x: 1/(1+np.exp(-x))\n","def eval_prm(candidates):\n","    all_log_probs = []\n","    for i in range(len(candidates)):\n","        input_ids = prm_tokenizer.encode(candidates[i], return_tensors=\"pt\").to(\"cuda:1\")\n","        with torch.no_grad():\n","            hidden_states = base_model(input_ids)[0][:,-1] # 1,l,d -> 1,d\n","            logits = prm_model.score(hidden_states)[0]\n","        all_log_probs.append(logit2prob(logits.item()))\n","    return all_log_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-18T15:36:45.089451Z","iopub.status.busy":"2024-05-18T15:36:45.088799Z","iopub.status.idle":"2024-05-18T15:36:45.171576Z","shell.execute_reply":"2024-05-18T15:36:45.170519Z","shell.execute_reply.started":"2024-05-18T15:36:45.089419Z"},"papermill":{"duration":34.259365,"end_time":"2024-02-29T09:37:05.548829","exception":false,"start_time":"2024-02-29T09:36:31.289464","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"source":["stop_words = [tokenizer.eos_token,\"```output\",\"```Output\",\"```output\\n\",\"```Output\\n\",\"```\\nOutput\" , \")\\n```\" , \"``````output\"]\n","# stop_words.append(\"\\n\")\n","sampling_params = SamplingParams(temperature=1,\n","                                 max_tokens=256,\n","                                #  min_tokens=32,\n","                                 stop=stop_words,\n","                                 include_stop_str_in_output=True\n","                                )\n","\n","def gen_prompt_codeIn1(problem):\n","    return f\"\"\"\n","Problem:{problem}\\n\n","Let's reason step by step and write Python (sympy) code to solve the problem, using brute force enumeration if necessary. \n","Limit the search space using logical deductions. The code should be enclosed between ```python\\n actual code...``` and should only print the final answer.\n","\"\"\"\n","\n","n = 3 # beams\n","n_sol = 3\n","samples = 7\n","max_depth = 20\n","max_pct = 0.88\n","timeout = 7\n","len_limit = 49\n","\n","\n","all_prompts = []\n","total_paths = []\n","total_answers = []\n","\n","def is_integer(num):\n","    if isinstance(num, float):\n","        return num.is_integer()\n","    elif isinstance(num, int):\n","        return True\n","    else:\n","        return False\n","    \n","def is_between_0_and_999(num):\n","    return 0 <= num <= 999\n","\n","import re\n","def extract_number(text):\n","    patterns = [\n","        r'[Tt]he answer is.*\\\\boxed\\{(.*?)\\}',\n","        r\"[Tt]he answer is[:\\s]*\\$([0-9]+)\\$\",\n","        r\"[Tt]he answer is[:\\s]*([0-9]+)\"\n","    ]\n","    for pattern in patterns:\n","        match = re.search(pattern, text)\n","        if match:\n","            return match.group(1)\n","    return 'parse err'\n","\n","def repeat_elements(lst, k):\n","    return [i for i in lst for _ in range(k)]\n","\n","def filter_input(batch_response,current_level_node):\n","    # one question filter\n","    prm_inputs = []\n","    for candidate,parent in zip(batch_response,current_level_node):\n","        if candidate.outputs[0].text not in parent:\n","            prm_input = parent + candidate.outputs[0].text\n","            prm_inputs.append(prm_input)\n","    # Get the indices of unique elements in prm_inputs\n","    unique_indices = [i for i, x in enumerate(prm_inputs) if prm_inputs.index(x) == i]\n","    prm_inputs = [prm_inputs[i] for i in unique_indices]\n","    return prm_inputs\n","\n","def IsFinished(node):\n","    matches = re.findall(r'print\\(([^)]*)\\)', node)\n","    return len(matches)>0\n","\n","def get_next_node(prm_inputs,prm_scores):\n","    # need to update completed_paths in-place\n","    if len(prm_inputs) == 0: return []\n","    next_level_nodes = []\n","    combined = list(zip(prm_inputs,prm_scores))\n","    combined.sort(key=lambda x: x[1], reverse=True)  # Sort nodes by their scores\n","    max_score = combined[0][1]\n","    for node,score in combined:\n","        finish = IsFinished(node)\n","        if finish: # finished\n","            if score > max_score * max_pct:\n","                completed_paths.append((score,node))\n","        else: # not inished\n","            if (len(next_level_nodes) < n) and (score > max_score * max_pct):\n","                next_level_nodes.append(node)\n","    return next_level_nodes\n","\n","import subprocess\n","import sys\n","def agg_code(paths):\n","    paths = [p for p in paths if p]\n","    paths.sort(key=lambda x: x[0], reverse=True)\n","    for path in paths:# path (score,node)\n","        if path:# not None\n","            input = path[1]\n","            if input[-12:]==\"print(result\": # stop token was not included. print(result) might miss a \")\"\n","                input += \")\"\n","            splits = input.split('```')\n","            if len(splits) <= 3: # 3 bc prompt include two ```\n","                continue\n","            code = \"from sympy import *\\n\" + input.split('```')[3][7:] \n","            if len(code) < len_limit: continue # ignore very short answer\n","\n","            # execute code\n","            with open('code.py', 'w') as fout:\n","                fout.write(code)\n","            # timeout err\n","            try:\n","                process = subprocess.run([sys.executable, 'code.py'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)\n","            except subprocess.TimeoutExpired:\n","                continue\n","            if process.stderr:# code.py err\n","                continue\n","            else:\n","                stdout = process.stdout.decode('utf8')\n","                try:\n","                    answer = eval(stdout)\n","                    if is_integer(answer) and is_between_0_and_999(answer):\n","                        return int(answer)\n","                    else:\n","                        continue\n","                except:\n","                    continue\n","    return 37\n","\n","for test, sample_submission in iter_test:\n","    problem = test['problem'].values[0]\n","\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": gen_prompt_codeIn1(problem)\n","        }\n","    ]\n","\n","    base_prompt = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False\n","    )\n","    current_level = 1\n","\n","    current_level_nodes = [base_prompt]\n","    completed_paths = []\n","    completed_path_splits = []\n","    try:\n","        while (len(completed_paths) < n_sol) and (current_level < max_depth) and (current_level_nodes):\n","            current_level_nodes = repeat_elements(current_level_nodes,samples)\n","            batch_responses = llm.generate(current_level_nodes, sampling_params)\n","            prm_inputs = filter_input(batch_responses,current_level_nodes)\n","            prm_scores = eval_prm(prm_inputs)\n","            current_level_nodes = get_next_node(prm_inputs,prm_scores)\n","        sample_submission['answer'] = agg_code(completed_paths)\n","    except:\n","        sample_submission['answer'] = 37\n","    env.predict(sample_submission)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# total_paths\n","# len(set(current_level_nodes)),len(current_level_nodes),len(set(prm_inputs)),len(prm_inputs)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8365361,"sourceId":73231,"sourceType":"competition"},{"datasetId":4728129,"sourceId":8023365,"sourceType":"datasetVersion"},{"datasetId":4746046,"sourceId":8300737,"sourceType":"datasetVersion"},{"modelInstanceId":3900,"sourceId":5112,"sourceType":"modelInstanceVersion"},{"modelInstanceId":4761,"sourceId":5994,"sourceType":"modelInstanceVersion"},{"modelInstanceId":8318,"sourceId":11382,"sourceType":"modelInstanceVersion"},{"modelInstanceId":8332,"sourceId":11394,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"papermill":{"default_parameters":{},"duration":724.728315,"end_time":"2024-02-29T09:37:08.760349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-29T09:25:04.032034","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"21267b653022419eb6fc3f47aa4db8ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926e7ccdad6440be85c76931860b744c","placeholder":"​","style":"IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67","value":"Loading checkpoint shards: 100%"}},"2144e851698b4707ad1c7fc29fe21b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963993becfa487c9ff725f211915e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065","placeholder":"​","style":"IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca","value":" 19/19 [10:48&lt;00:00, 33.24s/it]"}},"5882b6e860be4a0db012a64fc0704a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed","IPY_MODEL_d91eb83d016a4381828192a98f798f9b","IPY_MODEL_3963993becfa487c9ff725f211915e67"],"layout":"IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"}},"6a892a5561f742bb9db9f13859c18e90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926e7ccdad6440be85c76931860b744c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91eb83d016a4381828192a98f798f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0693b32889c42b18b9a3844e045d048","value":19}},"e0693b32889c42b18b9a3844e045d048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a725e1b0cc4ad78a62beab5f663065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb32baaed7145d8a8024b615ef242ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef8334edb24f6da22e8bb1d8d80c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
