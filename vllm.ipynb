{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e97f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T21:28:33.236687Z",
     "iopub.status.busy": "2024-04-03T21:28:33.235888Z",
     "iopub.status.idle": "2024-04-03T21:30:40.885067Z",
     "shell.execute_reply": "2024-04-03T21:30:40.884103Z"
    },
    "papermill": {
     "duration": 127.660006,
     "end_time": "2024-04-03T21:30:40.887589",
     "exception": false,
     "start_time": "2024-04-03T21:28:33.227583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    LOCAL = True\n",
    "    MODEL_PATH = \"deepseek-ai/deepseek-math-7b-rl\"\n",
    "    from functions import *\n",
    "    dtype = 'auto'\n",
    "    gpu_memory_utilization = 0.9\n",
    "except:\n",
    "    %pip uninstall -y torch -q\n",
    "    %pip install --no-index --find-links=/kaggle/input/vllm-whl -U vllm -q\n",
    "    from vllm import LLM, SamplingParams\n",
    "    LOCAL = False\n",
    "    MODEL_PATH = \"/kaggle/input/deepseek-math\"\n",
    "    dtype = 'half'\n",
    "    gpu_memory_utilization = 0.99\n",
    "    from functions_math import *\n",
    "    import gc\n",
    "\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817792b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-17 14:55:55 utils.py:253] CUDA_HOME is not found in the environment. Using /usr/local/cuda as CUDA_HOME.\n",
      "INFO 04-17 14:55:55 config.py:381] Using fp8_e5m2 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. But it may cause slight accuracy drop. Currently we only support fp8 without scaling factors and make e5m2 as a default format.\n",
      "INFO 04-17 14:55:55 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='deepseek-ai/deepseek-math-7b-rl', tokenizer='deepseek-ai/deepseek-math-7b-rl', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=fp8_e5m2, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-17 14:55:56 selector.py:51] Cannot use FlashAttention because the package is not found. Please install it for better performance.\n",
      "INFO 04-17 14:55:56 selector.py:25] Using XFormers backend.\n",
      "INFO 04-17 14:55:57 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "INFO 04-17 14:55:58 model_runner.py:104] Loading model weights took 12.8725 GB\n",
      "INFO 04-17 14:55:59 gpu_executor.py:94] # GPU blocks: 1989, # CPU blocks: 2730\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=MODEL_PATH,\n",
    "          dtype='auto',\n",
    "          enforce_eager=True,\n",
    "          gpu_memory_utilization=0.9,\n",
    "          swap_space=10,\n",
    "          max_model_len=2048,\n",
    "          kv_cache_dtype=\"fp8_e5m2\",\n",
    "          tensor_parallel_size=1)\n",
    "tokenizer = llm.get_tokenizer()\n",
    "stop_words = [tokenizer.eos_token]\n",
    "sampling_params = SamplingParams(n = 1, best_of= 1,\n",
    "                                 temperature=0,\n",
    "                                 max_tokens=1500,\n",
    "                                 stop=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26355039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T21:30:40.903909Z",
     "iopub.status.busy": "2024-04-03T21:30:40.903421Z",
     "iopub.status.idle": "2024-04-03T21:30:42.260344Z",
     "shell.execute_reply": "2024-04-03T21:30:42.259185Z"
    },
    "papermill": {
     "duration": 1.367528,
     "end_time": "2024-04-03T21:30:42.262807",
     "exception": false,
     "start_time": "2024-04-03T21:30:40.895279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOCAL:\n",
    "    import json\n",
    "    with open('../Data/AMC/aime_normal.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # to have consistent format as in Kaggle\n",
    "    data = pd.DataFrame(data)\n",
    "    data.rename(columns={'question': 'problem'}, inplace=True)\n",
    "else:\n",
    "    data = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/test.csv')\n",
    "    if len(data) < 5:\n",
    "        data = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n",
    "        PRIVATE = False\n",
    "    else:\n",
    "        PRIVATE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6644d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare inputs\n",
    "inputs = []\n",
    "for index, row in data.iterrows():\n",
    "    problem = row['problem']\n",
    "    query_prompt = gen_prompt(problem)\n",
    "    messages = [{\"role\": \"user\",\"content\": query_prompt}]\n",
    "    input = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs.append(input)\n",
    "\n",
    "# generation\n",
    "raw_outputs = llm.generate(inputs, sampling_params)\n",
    "\n",
    "# parse outputs\n",
    "outs = []\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    problem = row['problem']\n",
    "    decoded_output = raw_outputs[i].outputs[0].text\n",
    "    try:\n",
    "        answer = decoded_output.split('\\n')[-1]\n",
    "        answer = naive_parse(answer) % 1000\n",
    "    except:\n",
    "        answer = 'parsing error'\n",
    "\n",
    "    if LOCAL:\n",
    "        outs.append((problem,decoded_output,answer,int(row['final_answer'][0])))\n",
    "    else:\n",
    "        outs.append(37 if answer == 'parsing error' else answer)\n",
    "        if not PRIVATE:\n",
    "            print(decoded_output)\n",
    "            print(f'\\nanswer is {answer}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a513ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 51\n",
      "parse error: 116\n",
      "../llmOutputs/model4\n"
     ]
    }
   ],
   "source": [
    "if LOCAL:\n",
    "    outs_df = pd.DataFrame(outs,columns=['problem','output','yhat','y'])\n",
    "    print(f\"correct: {sum(outs_df.yhat == outs_df.y)}\")\n",
    "    print(f\"parse error: {sum(outs_df.yhat =='parsing error')}\")\n",
    "    out_path = create_next_model_folder('../llmOutputs')\n",
    "    print(out_path) # ../llmOutputs/model1\n",
    "    outs_df.to_csv(out_path+'/generations.csv', header=True, index=False)\n",
    "else:\n",
    "    if not PRIVATE:\n",
    "        answers = data.answer.tolist()\n",
    "        correct = sum([y==yhat for y,yhat in zip(answers,outs)])\n",
    "        print(f'{correct} correct answers')    \n",
    "    data['answer'] = outs\n",
    "    data[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8133715,
     "sourceId": 73231,
     "sourceType": "competition"
    },
    {
     "datasetId": 4281572,
     "sourceId": 7369493,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4727498,
     "isSourceIdPinned": true,
     "sourceId": 8022668,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 645.368853,
   "end_time": "2024-04-03T21:38:35.367254",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-03T21:27:49.998401",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08213ff2f3fe4dc58310902a0e714fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0063cf432324329b3ec56ac67170190",
       "placeholder": "​",
       "style": "IPY_MODEL_1c4f80ae8e4c4075ab1c0253b8bfe72b",
       "value": " 3/3 [01:51&lt;00:00, 36.32s/it]"
      }
     },
     "1c4f80ae8e4c4075ab1c0253b8bfe72b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "608f103f10f7493388c58f1022606b5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "698b2618c6cb44919194413c2013fa69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91954822b9664cfabc85f9bd4ca2a82a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_698b2618c6cb44919194413c2013fa69",
       "placeholder": "​",
       "style": "IPY_MODEL_608f103f10f7493388c58f1022606b5c",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "968fcd0a8c76415cb8b0910b41f82633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c824dd8e4ee14f53889e4e089ae2fa27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef6cee2682b74df7bbe38f0d3f105e1b",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_968fcd0a8c76415cb8b0910b41f82633",
       "value": 3
      }
     },
     "d0063cf432324329b3ec56ac67170190": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e841af56321d48eaad41c823c88647a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_91954822b9664cfabc85f9bd4ca2a82a",
        "IPY_MODEL_c824dd8e4ee14f53889e4e089ae2fa27",
        "IPY_MODEL_08213ff2f3fe4dc58310902a0e714fc7"
       ],
       "layout": "IPY_MODEL_fa01e68ebc80458bbe20fdac92c8285e"
      }
     },
     "ef6cee2682b74df7bbe38f0d3f105e1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa01e68ebc80458bbe20fdac92c8285e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
