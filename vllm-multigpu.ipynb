{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53827804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:27:39.153611Z",
     "iopub.status.busy": "2024-04-18T17:27:39.152924Z",
     "iopub.status.idle": "2024-04-18T17:30:00.648469Z",
     "shell.execute_reply": "2024-04-18T17:30:00.647367Z"
    },
    "papermill": {
     "duration": 141.505463,
     "end_time": "2024-04-18T17:30:00.651449",
     "exception": false,
     "start_time": "2024-04-18T17:27:39.145986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pynvml<11.5,>=11.0.0, but you have pynvml 11.5.0 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 17:29:59,636\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    LOCAL = True\n",
    "    MODEL_PATH = \"deepseek-ai/deepseek-math-7b-rl\"\n",
    "    from functions import *\n",
    "    dtype = 'auto'\n",
    "    gpu_memory_utilization = 0.9\n",
    "except:\n",
    "    %pip uninstall -y torch -q\n",
    "    %pip install --no-index --find-links=/kaggle/input/vllm-whl -U vllm -q\n",
    "    from vllm import LLM, SamplingParams\n",
    "    LOCAL = False\n",
    "    MODEL_PATH = \"/kaggle/input/deepseek-math\"\n",
    "    dtype = 'half'\n",
    "    gpu_memory_utilization = 0.99\n",
    "    from functions_math import *\n",
    "    import gc\n",
    "    import multiprocessing\n",
    "\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4989ac22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:30:00.667656Z",
     "iopub.status.busy": "2024-04-18T17:30:00.666484Z",
     "iopub.status.idle": "2024-04-18T17:30:00.952594Z",
     "shell.execute_reply": "2024-04-18T17:30:00.951677Z"
    },
    "papermill": {
     "duration": 0.296229,
     "end_time": "2024-04-18T17:30:00.954710",
     "exception": false,
     "start_time": "2024-04-18T17:30:00.658481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "          'model':MODEL_PATH,\n",
    "          'dtype':dtype,\n",
    "          'enforce_eager':True,\n",
    "          'gpu_memory_utilization':gpu_memory_utilization,\n",
    "#           'swap_space':6,\n",
    "          'max_model_len':2048,\n",
    "          'kv_cache_dtype':\"fp8_e5m2\",\n",
    "          'tensor_parallel_size':1\n",
    "}\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "repeats = 1\n",
    "# normalize = False\n",
    "stop_words = [tokenizer.eos_token]\n",
    "sampling_params = SamplingParams(n = repeats, best_of=repeats,\n",
    "                                 temperature=0,\n",
    "                                 max_tokens=1500,\n",
    "                                 stop=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e28391f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:30:00.967217Z",
     "iopub.status.busy": "2024-04-18T17:30:00.966893Z",
     "iopub.status.idle": "2024-04-18T17:30:00.974753Z",
     "shell.execute_reply": "2024-04-18T17:30:00.973912Z"
    },
    "papermill": {
     "duration": 0.016411,
     "end_time": "2024-04-18T17:30:00.976672",
     "exception": false,
     "start_time": "2024-04-18T17:30:00.960261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_GPUS = 2\n",
    "def run_inference_one_gpu(gpu_id, prompt_list, model_dict, sampling_params):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    llm = LLM(**model_dict)\n",
    "    return llm.generate(prompt_list, sampling_params)\n",
    "\n",
    "# Splits a list into roughly equally sized pieces\n",
    "# split_list([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"], 3) -> [['a', 'b'], ['c', 'd'], ['e', 'f', 'g']]\n",
    "split_list = lambda l, n: [l[i * len(l) // n: (i + 1) * len(l) // n] for i in range(n)]\n",
    "\n",
    "def run_inference_multi_gpu(prompts, model_dict, sampling_params):\n",
    "    split_prompts = split_list(prompts, NUM_GPUS)\n",
    "    inputs = [(i, p, model_dict, sampling_params) for i, p in enumerate(split_prompts)]\n",
    "\n",
    "    with multiprocessing.Pool(processes=NUM_GPUS) as pool:\n",
    "        results = pool.starmap(run_inference_one_gpu, inputs)\n",
    "\n",
    "    outputs = []\n",
    "    for result in results:\n",
    "        outputs.extend(result)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06c1ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:30:00.988630Z",
     "iopub.status.busy": "2024-04-18T17:30:00.988363Z",
     "iopub.status.idle": "2024-04-18T17:30:01.006806Z",
     "shell.execute_reply": "2024-04-18T17:30:01.006052Z"
    },
    "papermill": {
     "duration": 0.027138,
     "end_time": "2024-04-18T17:30:01.009045",
     "exception": false,
     "start_time": "2024-04-18T17:30:00.981907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOCAL:\n",
    "    import json\n",
    "    with open('../Data/AMC/aime_normal.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # to have consistent format as in Kaggle\n",
    "    data = pd.DataFrame(data)\n",
    "    data.rename(columns={'question': 'problem'}, inplace=True)\n",
    "else:\n",
    "    data = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/test.csv')\n",
    "    if len(data) < 5:\n",
    "        data = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n",
    "        PRIVATE = False\n",
    "    else:\n",
    "        PRIVATE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7420a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:30:01.021338Z",
     "iopub.status.busy": "2024-04-18T17:30:01.021042Z",
     "iopub.status.idle": "2024-04-18T17:33:50.239102Z",
     "shell.execute_reply": "2024-04-18T17:33:50.237462Z"
    },
    "papermill": {
     "duration": 229.228373,
     "end_time": "2024-04-18T17:33:50.243199",
     "exception": false,
     "start_time": "2024-04-18T17:30:01.014826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-18 17:30:01 config.py:767] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 04-18 17:30:01 config.py:767] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-18 17:30:01 config.py:381] Using fp8_e5m2 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. But it may cause slight accuracy drop. Currently we only support fp8 without scaling factors and make e5m2 as a default format.\n",
      "INFO 04-18 17:30:01 config.py:381] Using fp8_e5m2 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. But it may cause slight accuracy drop. Currently we only support fp8 without scaling factors and make e5m2 as a default format.\n",
      "INFO 04-18 17:30:01 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='/kaggle/input/deepseek-math', tokenizer='/kaggle/input/deepseek-math', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=fp8_e5m2, device_config=cuda, seed=0)\n",
      "INFO 04-18 17:30:01 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='/kaggle/input/deepseek-math', tokenizer='/kaggle/input/deepseek-math', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=fp8_e5m2, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-18 17:30:03 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 04-18 17:30:03 selector.py:25] Using XFormers backend.\n",
      "INFO 04-18 17:30:03 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 04-18 17:30:03 selector.py:25] Using XFormers backend.\n",
      "INFO 04-18 17:32:04 model_runner.py:104] Loading model weights took 12.8725 GB\n",
      "INFO 04-18 17:32:05 model_runner.py:104] Loading model weights took 12.8725 GB\n",
      "INFO 04-18 17:32:06 gpu_executor.py:94] # GPU blocks: 177, # CPU blocks: 1092\n",
      "INFO 04-18 17:32:06 gpu_executor.py:94] # GPU blocks: 177, # CPU blocks: 1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 5/5 [01:19<00:00, 15.92s/it]\n",
      "Processed prompts: 100%|██████████| 5/5 [01:34<00:00, 18.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. This means that the solutions of the equation $kx^2 - 2kx + l - 4 = 0$ are the x-coordinates of points $A$ and $B$. Let's call these solutions $x_1$ and $x_2$. We know that the distance between $A$ and $B$ is 6, so $|x_2 - x_1| = 6$. By Vieta's formulas, we know that $x_1 + x_2 = \\frac{2k}{k} = 2$ and $x_1x_2 = \\frac{l - 4}{k}$.\n",
      "\n",
      "Now, we want to find the sum of the squares of the distances from $A$ and $B$ to the origin. The distance from a point $(x, y)$ to the origin is $\\sqrt{x^2 + y^2}$. So the square of the distance from point $A$ (with x-coordinate $x_1$) to the origin is $x_1^2 + (kx_1^2 - 2kx_1 + l)^2 = x_1^2 + k^2x_1^4 - 4k^2x_1^3 + 4k^2x_1^2 + (l - 2kx_1)^2$. Similarly, the square of the distance from point $B$ to the origin is $x_2^2 + k^2x_2^4 - 4k^2x_2^3 + 4k^2x_2^2 + (l - 2kx_2)^2$.\n",
      "\n",
      "The sum of the squares of the distances from $A$ and $B$ to the origin is then\n",
      "\\[(x_1^2 + k^2x_1^4 - 4k^2x_1^3 + 4k^2x_1^2 + (l - 2kx_1)^2) + (x_2^2 + k^2x_2^4 - 4k^2x_2^3 + 4k^2x_2^2 + (l - 2kx_2)^2).\\]\n",
      "\n",
      "We can simplify this expression by using the fact that $x_1 + x_2 = 2$ and $x_1x_2 = \\frac{l - 4}{k}$. After simplifying, we get\n",
      "\\[4 + 4k^2(x_1^2 + x_2^2) + 2(l - 4k)^2.\\]\n",
      "\n",
      "We know that $(x_1 - x_2)^2 = (x_1 + x_2)^2 - 4x_1x_2 = 4 - 4\\frac{l - 4}{k} = \\frac{16 - 4l + 16}{k} = \\frac{32 - 4l}{k}$. But we also know that $(x_1 - x_2)^2 = 6^2 = 36$, so $\\frac{32 - 4l}{k} = 36$. Solving for $l$, we get $l = \\frac{32 - 36k}{4} = 8 - 9k$.\n",
      "\n",
      "Substituting $l = 8 - 9k$ into the expression for the sum of the squares of the distances, we get\n",
      "\\[4 + 4k^2(x_1^2 + x_2^2) + 2(8 - 4k - 9k)^2 = 4 + 4k^2(4 - 2\\cdot \\frac{l - 4}{k}) + 2(0)^2 = 4 + 4k^2(4 - 2\\cdot \\frac{8 - 9k - 4}{k}) = 4 + 4k^2(4 - 2\\cdot \\frac{4 - 9k}{k}) = 4 + 4k^2(4 - 8 + 18) = 4 + 4k^2(18) = 76k^2.\\]\n",
      "\n",
      "So the sum of the squares of the distances from $A$ and $B$ to the origin is $76k^2$. But we know that $l = 8 - 9k$, so we can substitute this back into the equation $kx^2 - 2kx + l - 4 = 0$ to get $kx^2 - 2kx + 8 - 9k - 4 = 0$, or $kx^2 - 2kx + 4 - 9k = 0$. This is a quadratic equation, and its discriminant must be nonnegative, so $(2k)^2 - 4k(4 - 9k) \\geq 0$. Simplifying, we get $4k^2 - 16k + 36k^2 \\geq 0$, or $36k^2 - 16k \\geq 0$. Factoring, we get $16k(2.25k - 1) \\geq 0$. This inequality is satisfied for $k \\geq \\frac{4}{9}$.\n",
      "\n",
      "So the sum of the squares of the distances from $A$ and $B$ to the origin is $76k^2$. Since $k \\geq \\frac{4}{9}$, the minimum value of $76k^2$ is achieved when $k = \\frac{4}{9}$. Substituting this value into $76k^2$, we get $76\\left(\\frac{4}{9}\\right)^2 = \\frac{76 \\cdot 16}{81} = \\frac{1216}{81}$.\n",
      "\n",
      "Therefore, the sum of the squares of the distances from $A$ and $B$ to the origin is $\\frac{1216}{81}$.\n",
      "The answer is $\\frac{1216}{81}$.\n",
      "\n",
      "answer is 81\n",
      "The maximum possible number of yellow numbers is 111.\n",
      "\n",
      "To see why, consider the number 111. If we color 111 yellow, then the sum of any two yellow numbers will be a number that is at least twice 111, which is 222. But 222 is greater than 999, so it's not in the range of the numbers we're considering. Therefore, the sum of any two yellow numbers must be less than 222.\n",
      "\n",
      "Now, let's consider the number 111 again. If we color 111 yellow, then the sum of any other yellow number and 111 must be a blue number. This means that the difference between any blue number and 111 must be a yellow number.\n",
      "\n",
      "Let's consider the smallest blue number, which is 112. The difference between 112 and 111 is 1, which is a yellow number. Now, let's consider the next smallest blue number, which is 113. The difference between 113 and 111 is 2, which is also a yellow number. We can continue this process for all the blue numbers up to 999.\n",
      "\n",
      "Therefore, the maximum possible number of yellow numbers is 111. The answer is: 111\n",
      "\n",
      "answer is 111\n",
      "We are looking for numbers whose sparkle eventually becomes a number less than 6.\n",
      "\n",
      "Let's consider the numbers 0, 1, 2, 3, 4, and 5. The sparkle of any of these numbers is less than 6.\n",
      "\n",
      "Now let's consider a number with more than one digit. The sparkle of a number is the factorial of the sum of its digits. The factorial function grows very quickly, so if the sum of the digits of a number is greater than 4, the sparkle of that number will be greater than 5, and will not be one of the numbers we are looking for.\n",
      "\n",
      "Therefore, we only need to consider numbers with a digit sum of 4 or less. The maximum digit sum for a number with 36 digits is 36 (if all the digits are 9), so we only need to consider numbers with a digit sum of 4 or less.\n",
      "\n",
      "The numbers with a digit sum of 4 are: 1111, 211, 121, 112, 22, 41, 14, 31, 13, and 21.\n",
      "\n",
      "So there are 10 special numbers with at most 36 digits. The answer is $\\boxed{10}$.\n",
      "\n",
      "answer is 10\n",
      "First, we can rewrite the given equation as $|x-2y| + |y-2x| = 40$.\n",
      "\n",
      "By the triangle inequality, we know that $|a| + |b| \\geq |a+b|$ for all real numbers $a$ and $b$. So, we have\n",
      "\n",
      "$$|x-2y| + |y-2x| \\geq |(x-2y) + (y-2x)| = |-x - y| = |-(x+y)| = |x+y|.$$\n",
      "\n",
      "Therefore, we have $|x+y| = 40$.\n",
      "\n",
      "Now, let's consider the expression $5x^2+5y^2-8xy$. We can rewrite it as\n",
      "\n",
      "$$5x^2+5y^2-8xy = \\frac{1}{2}(10x^2+10y^2-16xy) = \\frac{1}{2}((2x-4y)^2+(4y-2x)^2).$$\n",
      "\n",
      "By the Cauchy-Schwarz inequality, we have\n",
      "\n",
      "$$(a^2+b^2)(c^2+d^2) \\geq (ac+bd)^2$$ for all real numbers $a$, $b$, $c$, and $d$.\n",
      "\n",
      "Applying the Cauchy-Schwarz inequality with $a=2x-4y$, $b=4y-2x$, $c=1$, and $d=1$, we get\n",
      "\n",
      "$$((2x-4y)^2+(4y-2x)^2) \\geq (|2x-4y| + |4y-2x|)^2 = 40^2 = 1600.$$\n",
      "\n",
      "Therefore, we have\n",
      "\n",
      "$$5x^2+5y^2-8xy \\geq \\frac{1}{2} \\cdot 1600 = 800.$$\n",
      "\n",
      "So, the minimum value of $5x^2+5y^2-8xy$ is 800. The answer is $\\boxed{800}$.\n",
      "\n",
      "answer is 800\n",
      "The unique increasing geometric sequence of five 2-digit positive integers is $2^1, 2^2, 2^3, 2^4, 2^5$.\n",
      "\n",
      "The first term is $2^1 = 2$, the second term is $2^2 = 4$, the third term is $2^3 = 8$, the fourth term is $2^4 = 16$, and the fifth term is $2^5 = 32$.\n",
      "\n",
      "To find the sum of these terms, we simply add them together: $2 + 4 + 8 + 16 + 32 = 62$.\n",
      "\n",
      "So the sum of the unique increasing geometric sequence of five 2-digit positive integers is 62. The answer is $\\boxed{62}$.\n",
      "\n",
      "answer is 62\n",
      "The equation $\\vert \\vert x-1 \\vert -2 \\vert=\\frac{m}{100}$ has 4 distinct solutions if and only if $\\frac{m}{100}$ is strictly between 1 and 2. This is because the function $f(x) = \\vert \\vert x-1 \\vert -2 \\vert$ has a graph that is a \"V\" shape with the \"valleys\" at $x=1$ and $x=3$, and the distance between the \"valleys\" is 2. So for the equation to have 4 distinct solutions, the right side of the equation, $\\frac{m}{100}$, must be strictly between 1 and 2.\n",
      "\n",
      "If $\\frac{m}{100}$ is strictly between 1 and 2, then $1 < \\frac{m}{100} < 2$. Multiplying all sides of the inequalities by 100 gives $100 < m < 200$. The positive integers $m$ that satisfy this inequality are the integers from 101 to 199, inclusive. There are $199 - 101 + 1 = 99$ such integers.\n",
      "\n",
      "So the number of positive integers $m$ for which the equation $\\vert \\vert x-1 \\vert -2 \\vert=\\frac{m}{100}$ has 4 distinct solutions is 99. The answer is: $99$.\n",
      "\n",
      "answer is 99\n",
      "The total number of outcomes when rolling four 6-sided dice is $6^4 = 1296$.\n",
      "\n",
      "The event that the highest roll is a 5 means that at least one of the dice shows a 5, and the other three dice show any number from 1 to 4. The number of ways to roll a 5 on one die and any number from 1 to 4 on the other three dice is $\\binom{4}{1} \\cdot 5^3 = 500$.\n",
      "\n",
      "Therefore, the probability that the highest roll is a 5 is $\\frac{500}{1296}$.\n",
      "\n",
      "To express this in the form $a/b$ where $a$ and $b$ are relatively prime, we simplify the fraction $\\frac{500}{1296}$.\n",
      "\n",
      "The greatest common divisor of 500 and 1296 is 4, so we divide both the numerator and the denominator by 4 to get $\\frac{125}{324}$.\n",
      "\n",
      "Therefore, the probability that the highest roll is a 5 is $\\frac{125}{324}$.\n",
      "\n",
      "Finally, we need to find $a + b$, where $a = 125$ and $b = 324$. So, $a + b = 125 + 324 = 449$.\n",
      "The answer is $\\boxed{449}$.\n",
      "\n",
      "answer is 449\n",
      "The expression $((\\vert x + y \\vert - 10)^2 + ( \\vert x - y \\vert - 10)^2)((\\vert x \\vert - 8)^2 + ( \\vert y \\vert - 8)^2) = 0$ is equal to zero if and only if at least one of the factors is equal to zero. This means that either $(\\vert x + y \\vert - 10)^2 + ( \\vert x - y \\vert - 10)^2 = 0$ or $(\\vert x \\vert - 8)^2 + ( \\vert y \\vert - 8)^2 = 0$.\n",
      "\n",
      "If $(\\vert x + y \\vert - 10)^2 + ( \\vert x - y \\vert - 10)^2 = 0$, then $\\vert x + y \\vert = 10$ and $\\vert x - y \\vert = 10$. This means that $x + y = \\pm 10$ and $x - y = \\pm 10$. Solving these equations gives us the vertices of the square: $(0, 10)$, $(0, -10)$, $(10, 0)$, and $(-10, 0)$.\n",
      "\n",
      "If $(\\vert x \\vert - 8)^2 + ( \\vert y \\vert - 8)^2 = 0$, then $\\vert x \\vert = 8$ and $\\vert y \\vert = 8$. This means that $x = \\pm 8$ and $y = \\pm 8$. Solving these equations gives us the vertices of the square: $(8, 0)$, $(-8, 0)$, $(0, 8)$, and $(0, -8)$.\n",
      "\n",
      "Therefore, the points $\\left(x, y\\right)$ that satisfy the given equation form a square with side length $10$. The area of this square is $10^2 = 100$. So the area of the convex polygon is $100$. The answer is: $100$.\n",
      "\n",
      "answer is 100\n",
      "The area of the unit square is 1. The area of triangle $ABQ$ is $\\frac{1}{2} \\cdot 1 \\cdot \\frac{1}{24} = \\frac{1}{48}$. The area of triangle $ADP$ is $\\frac{1}{2} \\cdot 1 \\cdot \\frac{1}{20} = \\frac{1}{40}$. The area of the quadrilateral $PBQD$ is $1 - \\left(\\frac{1}{48} + \\frac{1}{40}\\right) = 1 - \\frac{48 + 40}{48 \\cdot 40} = 1 - \\frac{88}{24 \\cdot 40} = 1 - \\frac{11}{240} = \\frac{229}{240}$.\n",
      "\n",
      "The largest region is the triangle $PBQ$, which has area $\\frac{1}{48}$. The smallest region is the quadrilateral $PBQD$, which has area $\\frac{229}{240}$.\n",
      "\n",
      "Therefore, the ratio of the areas of the largest region to the smallest region is $\\frac{\\frac{1}{48}}{\\frac{229}{240}} = \\frac{1}{48} \\cdot \\frac{240}{229} = \\frac{240}{48 \\cdot 229} = \\frac{5}{229}$.\n",
      "\n",
      "So the ratio of the areas of the largest region to the smallest region is $\\frac{5}{229}$. The answer is $\\frac{5}{229}$.\n",
      "\n",
      "answer is 229\n",
      "First, we can use the second equation to find $f(100)$. We know that $f(2 \\cdot 50) = 2f(50) + 1$. So, $f(100) = 2f(50) + 1$.\n",
      "\n",
      "Next, we can use the first equation to find $f(50)$. We know that $f(f(f(50))) = 8 \\cdot 50 - 7 = 393$. Since $f(f(f(50))) = f(f(100)) = f(2f(50) + 1)$, we have $f(2f(50) + 1) = 393$.\n",
      "\n",
      "Now, let's substitute $f(100) = 2f(50) + 1$ into this equation to get $f(2f(50) + 1) = f(f(100)) = 393$.\n",
      "\n",
      "This is a bit tricky, but we can solve it step by step. Let $x = f(50)$, then the equation becomes $f(2x + 1) = 393$.\n",
      "\n",
      "We know that $f(f(f(x))) = 8x - 7$, so $f(f(f(2x + 1))) = 8(2x + 1) - 7 = 16x + 1$.\n",
      "\n",
      "But $f(f(f(2x + 1))) = f(f(393)) = f(2f(196.5) + 1)$.\n",
      "\n",
      "Since $f(x)$ is defined only for natural numbers, $f(196.5)$ is not defined. However, we can notice that $196.5 = \\frac{393 + 1}{2}$, so we can guess that $f(x) = \\frac{x - 1}{2}$ for all odd $x$.\n",
      "\n",
      "If $f(x) = \\frac{x - 1}{2}$ for all odd $x$, then $f(393) = \\frac{393 - 1}{2} = 196$, and $f(196) = \\frac{196 - 1}{2} = 97.5$, which is not a natural number. So, our guess is incorrect.\n",
      "\n",
      "However, we can notice that $f(f(f(x))) = 8x - 7$ is equivalent to $f(f(x)) = 2x - 1$, because $f(f(f(x))) = f(2x - 1) = 8x - 7$.\n",
      "\n",
      "If we let $f(x) = \\frac{x - 1}{2}$ for all even $x$, then $f(2x) = \\frac{2x - 1}{2} = x - \\frac{1}{2}$, which is not an integer, so our guess is incorrect again.\n",
      "\n",
      "However, if we let $f(x) = \\frac{x + 1}{2}$ for all even $x$, then $f(2x) = \\frac{2x + 1}{2} = x + \\frac{1}{2}$, which is not an integer either.\n",
      "\n",
      "If we let $f(x) = \\frac{x - 1}{2}$ for all even $x$, then $f(2x) = \\frac{2x - 1}{2} = x - \\frac{1}{2}$, which is an integer.\n",
      "\n",
      "So, we guess that $f(x) = \\frac{x - 1}{2}$ for all even $x$, and $f(x) = \\frac{x + 1}{2}$ for all odd $x$.\n",
      "\n",
      "Now, let's check if this guess works. If $x = 50$ is even, then $f(50) = \\frac{50 - 1}{2} = 24.5$, which is not an integer. So, our guess is incorrect again.\n",
      "\n",
      "However, if we let $f(x) = \\frac{x - 1}{2}$ for all odd $x$, and $f(x) = \\frac{x + 1}{2}$ for all even $x$, then everything works out.\n",
      "\n",
      "So, $f(50) = \\frac{50 - 1}{2} = 24.5$, which is not an integer. So, our guess is incorrect again.\n",
      "\n",
      "If we let $f(x) = \\frac{x - 1}{2}$ for all odd $x$, and $f(x) = \\frac{x + 1}{2}$ for all even $x$, then everything works out.\n",
      "\n",
      "So, $f(50) = \\frac{50 + 1}{2} = 25.5$, which is not an integer. So, our guess is incorrect again.\n",
      "\n",
      "If we let $f(x) = \\frac{x + 1}{2}$ for all odd $x$, and $f(x) = \\frac{x - 1}{2}$ for all even $x$, then everything works out.\n",
      "\n",
      "So, $f(50) = \\frac{50 - 1}{2} = 24.5$, which is not an integer. So, our guess is incorrect again.\n",
      "\n",
      "If we let $f(x) = \\frac{x + 1}{2}$ for all odd $x$, and $f(x) = \\frac{x - 1}{2}$ for all even $x$, then everything works out.\n",
      "\n",
      "So, $f(50) = \\frac{50 - 1}{2} = 24.5$, which is not an integer. So, our guess is incorrect again.\n",
      "\n",
      "If we let $f(x) = \\frac{x + 1}{2}$ for all odd $x$, and $f(x) = \\frac{x - 1}{2}$ for all even $x$, then everything works out.\n",
      "\n",
      "So, $f(50) = \\frac{50 - 1}{2} = 24.5$, which is not an integer. So, our guess is incorrect again.\n",
      "\n",
      "If we let $f(x) = \\frac{x + 1}{2}$ for all odd $x$, and $f(x) = \\frac{x - 1}{2}$ for all even $x$, then everything works out.\n",
      "\n",
      "So, $f(50) = \\frac{50 + 1}{2} = 25.5$,\n",
      "\n",
      "answer is 5\n"
     ]
    }
   ],
   "source": [
    "# prepare inputs\n",
    "inputs = []\n",
    "for index, row in data.iterrows():\n",
    "    problem = row['problem']\n",
    "    query_prompt = gen_prompt(problem)\n",
    "    messages = [{\"role\": \"user\",\"content\": query_prompt}]\n",
    "    input = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs.append(input)\n",
    "\n",
    "# generation\n",
    "raw_outputs = run_inference_multi_gpu(inputs, model_dict, sampling_params)\n",
    "\n",
    "# parse outputs\n",
    "outs = []\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    problem = row['problem']\n",
    "    decoded_output = raw_outputs[i].outputs[0].text\n",
    "    try:\n",
    "        answer = decoded_output.split('\\n')[-1]\n",
    "        answer = naive_parse(answer) % 1000\n",
    "    except:\n",
    "        answer = 'parsing error'\n",
    "\n",
    "    if LOCAL:\n",
    "        outs.append((problem,decoded_output,answer,int(row['final_answer'][0])))\n",
    "    else:\n",
    "        outs.append(37 if answer == 'parsing error' else answer)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        if not PRIVATE:\n",
    "            print(decoded_output)\n",
    "            print(f'\\nanswer is {answer}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d05efc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:33:50.263317Z",
     "iopub.status.busy": "2024-04-18T17:33:50.262834Z",
     "iopub.status.idle": "2024-04-18T17:33:50.300561Z",
     "shell.execute_reply": "2024-04-18T17:33:50.299640Z"
    },
    "papermill": {
     "duration": 0.050712,
     "end_time": "2024-04-18T17:33:50.302608",
     "exception": false,
     "start_time": "2024-04-18T17:33:50.251896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 correct answers\n"
     ]
    }
   ],
   "source": [
    "if LOCAL:\n",
    "    outs_df = pd.DataFrame(outs,columns=['problem','output','yhat','y'])\n",
    "    print(f\"correct: {sum(outs_df.yhat == outs_df.y)}\")\n",
    "    print(f\"parse error: {sum(outs_df.yhat =='parsing error')}\")\n",
    "    out_path = create_next_model_folder('../llmOutputs')\n",
    "    print(out_path) # ../llmOutputs/model1\n",
    "    outs_df.to_csv(out_path+'/generations.csv', header=True, index=False)\n",
    "else:\n",
    "    if not PRIVATE:\n",
    "        answers = data.answer.tolist()\n",
    "        correct = sum([y==yhat for y,yhat in zip(answers,outs)])\n",
    "        print(f'{correct} correct answers')    \n",
    "    data['answer'] = outs\n",
    "    data[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8133715,
     "sourceId": 73231,
     "sourceType": "competition"
    },
    {
     "datasetId": 4728129,
     "sourceId": 8023365,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4746046,
     "sourceId": 8077274,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 172559828,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 377.509872,
   "end_time": "2024-04-18T17:33:53.527241",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-18T17:27:36.017369",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08213ff2f3fe4dc58310902a0e714fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0063cf432324329b3ec56ac67170190",
       "placeholder": "​",
       "style": "IPY_MODEL_1c4f80ae8e4c4075ab1c0253b8bfe72b",
       "value": " 3/3 [01:51&lt;00:00, 36.32s/it]"
      }
     },
     "1c4f80ae8e4c4075ab1c0253b8bfe72b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "608f103f10f7493388c58f1022606b5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "698b2618c6cb44919194413c2013fa69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91954822b9664cfabc85f9bd4ca2a82a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_698b2618c6cb44919194413c2013fa69",
       "placeholder": "​",
       "style": "IPY_MODEL_608f103f10f7493388c58f1022606b5c",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "968fcd0a8c76415cb8b0910b41f82633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c824dd8e4ee14f53889e4e089ae2fa27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef6cee2682b74df7bbe38f0d3f105e1b",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_968fcd0a8c76415cb8b0910b41f82633",
       "value": 3
      }
     },
     "d0063cf432324329b3ec56ac67170190": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e841af56321d48eaad41c823c88647a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_91954822b9664cfabc85f9bd4ca2a82a",
        "IPY_MODEL_c824dd8e4ee14f53889e4e089ae2fa27",
        "IPY_MODEL_08213ff2f3fe4dc58310902a0e714fc7"
       ],
       "layout": "IPY_MODEL_fa01e68ebc80458bbe20fdac92c8285e"
      }
     },
     "ef6cee2682b74df7bbe38f0d3f105e1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa01e68ebc80458bbe20fdac92c8285e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
